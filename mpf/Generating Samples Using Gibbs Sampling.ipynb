{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Samples\n",
    "----\n",
    "### Introduction\n",
    "Here we want to generate binary samples of length $v$ using Gibbs sampling based on a prior distribution based on a $v \\times v$ matrix $W$ initialized from a known distribution. Using the samples generated, we would eventually want to reproduce/learn the matrix $W$ from the samples using minimum probability flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import time\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall consider a network with $v$ vertices where each vertex is binary. For a network with $v$ vertices, there are $2^v$ possibles binary states. We initialize an initial state of the network using the Bernoulli distribution with success probability $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of neurons:\n",
    "v = 16\n",
    "# Success probability:\n",
    "p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial states:  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "initialState = np.random.binomial(1, p, v)\n",
    "initialState = initialState.reshape(v,1)\n",
    "print ('Initial states: ',initialState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize a $v$ by $v$ matrix $W$ with each entry drawn from a standard normal distribution, $N(0,1)$. For each entry in the matrix, $W_{ij}$ denotes the parameter/weight associated with the connection from unit $i$ to $j$ (can we think of it as the conditional weight of $v^{(t+1)}_i=1$ given $v^{(t)}_j=1$?). Here we save the matrix $W$ so we can verify the learning by MPF. \n",
    "\n",
    "(Personal notes: Later, we will learn that initializing the matrix $W$ with zero diagonals will make it easier in the generation of samples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.94711814  0.04547612  0.31349768  1.02249207 -1.07121386\n",
      "   0.48029422 -0.50629145  0.28453795  1.39687164 -0.17699444  0.32543192\n",
      "   0.36087745  0.20079981 -0.54846689 -0.15188135]\n",
      " [ 0.94711814 -0.20515826 -0.83386438 -0.53341801 -1.47738538  0.77722254\n",
      "   1.32515335  0.58394997  1.33860823 -0.25494309  0.98764529 -0.43836681\n",
      "   0.18234286  0.68560419  0.10910471 -0.00955465]\n",
      " [ 0.04547612 -0.83386438 -0.34791215 -0.3695588  -0.19995383  0.83402114\n",
      "  -0.13020736 -0.28515306 -0.90923452 -1.16642008 -0.37842469  0.74762145\n",
      "   0.00681224  0.2360523  -0.54814441  0.32230489]\n",
      " [ 0.31349768 -0.53341801 -0.3695588   0.3869025  -0.02401144 -1.35843794\n",
      "   0.18690357  0.61539413  0.30288321  0.70974409 -0.27338543 -0.172631\n",
      "  -0.42200339 -0.02116747 -0.29048262 -1.01203674]\n",
      " [ 1.02249207 -1.47738538 -0.19995383 -0.02401144 -0.90729836  0.77009879\n",
      "   1.30612063  0.53811744  0.23253401 -1.27536662 -0.41154694 -0.519402\n",
      "  -0.0495033   0.10373915 -0.4544343  -0.12642381]\n",
      " [-1.07121386  0.77722254  0.83402114 -1.35843794  0.77009879  1.89588918\n",
      "  -0.08448974 -0.16746746 -0.51946103  0.29643356  0.22059301 -0.07625311\n",
      "   0.51588957  0.25510997  0.05922233 -0.48471532]\n",
      " [ 0.48029422  1.32515335 -0.13020736  0.18690357  1.30612063 -0.08448974\n",
      "  -1.270485    0.79173804 -0.90448474  0.93768979 -0.70691716 -0.69553661\n",
      "   2.04308899  0.26803427  0.22174903  1.02918811]\n",
      " [-0.50629145  0.58394997 -0.28515306  0.61539413  0.53811744 -0.16746746\n",
      "   0.79173804  0.92220667  0.52642941  0.30697097 -0.62326646 -0.44850863\n",
      "   0.32098004 -0.27984212 -0.46423672  1.46444116]\n",
      " [ 0.28453795  1.33860823 -0.90923452  0.30288321  0.23253401 -0.51946103\n",
      "  -0.90448474  0.52642941  0.57659082 -0.47652679  0.79201825 -0.23391503\n",
      "  -0.93021972  0.21118564 -0.18809399 -0.08916641]\n",
      " [ 1.39687164 -0.25494309 -1.16642008  0.70974409 -1.27536662  0.29643356\n",
      "   0.93768979  0.30697097 -0.47652679 -0.82643854  0.10924504 -1.13276797\n",
      "   0.44362837 -0.35038989 -0.3657093  -0.95212219]\n",
      " [-0.17699444  0.98764529 -0.37842469 -0.27338543 -0.41154694  0.22059301\n",
      "  -0.70691716 -0.62326646  0.79201825  0.10924504  0.92085882 -0.39282784\n",
      "   0.9782451   0.80414168 -1.09521264  0.6013297 ]\n",
      " [ 0.32543192 -0.43836681  0.74762145 -0.172631   -0.519402   -0.07625311\n",
      "  -0.69553661 -0.44850863 -0.23391503 -1.13276797 -0.39282784  0.05216508\n",
      "  -0.04214963  0.75037872 -0.2558294  -0.15436855]\n",
      " [ 0.36087745  0.18234286  0.00681224 -0.42200339 -0.0495033   0.51588957\n",
      "   2.04308899  0.32098004 -0.93021972  0.44362837  0.9782451  -0.04214963\n",
      "   0.64013153 -1.28645052  0.73507921 -0.29803887]\n",
      " [ 0.20079981  0.68560419  0.2360523  -0.02116747  0.10373915  0.25510997\n",
      "   0.26803427 -0.27984212  0.21118564 -0.35038989  0.80414168  0.75037872\n",
      "  -1.28645052 -0.34598178 -1.2667905   0.08107653]\n",
      " [-0.54846689  0.10910471 -0.54814441 -0.29048262 -0.4544343   0.05922233\n",
      "   0.22174903 -0.46423672 -0.18809399 -0.3657093  -1.09521264 -0.2558294\n",
      "   0.73507921 -1.2667905   0.42625873  0.68422339]\n",
      " [-0.15188135 -0.00955465  0.32230489 -1.01203674 -0.12642381 -0.48471532\n",
      "   1.02918811  1.46444116 -0.08916641 -0.95212219  0.6013297  -0.15436855\n",
      "  -0.29803887  0.08107653  0.68422339  0.69474914]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Get a symmetric matrix with diagonal all zeros\n",
    "W = np.random.normal(0, 1, (v,v))\n",
    "W = 0.5 * (W + np.transpose(W))\n",
    "\n",
    "# To save and load W matrix\n",
    "np.save('W.dat', W)\n",
    "# W = np.load('W.dat')\n",
    "print (W)\n",
    "\n",
    "b = np.zeros((v,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do Gibbs Sampling\n",
    "The reason for doing Gibbs sampling is to generate samples $\\mathcal{S}$ from known parameters $W$ and then use MPF to learn the parameters $W$ using $\\mathcal{S}$. To sample from this multivariate distribution, we start with an initial state obtained from a prior belief, following which sampling from the conditional distribution is done to get a new state of a **vertex**. Thus if we were to sample each vertex sequentially, a network with $v$ vertices would require sampling from (different) conditional distributions $v$ times for a new state of the network to be obtained.\n",
    "\n",
    "#### Algorithm: Gibbs sampler (cycle)\n",
    "1. Initialize $\\mathbf{x^{(0)}}=(x_1^{(0)},\\ldots,x_v^{(0)})$ base on some prior belief.\n",
    "2. For $i = 1,2, \\ldots$\n",
    "    - sample $X_1^{(i)}\\sim \\mathbb{P}(X_1^{(i)}=x_1^{(i)}\\mid X_2=x_2^{(i-1)},\\ldots,X_v=x_v^{(i-1)})$\n",
    "    - sample $X_2^{(i)}\\sim \\mathbb{P}(X_2^{(i)}=x_2^{(i)}\\mid X_1=x_1^{(i)},X_3=x_3^{(i-1)}\\ldots,X_v=x_v^{(i-1)})$\n",
    "    - in general, sample $X_j^{(i)}\\sim \\mathbb{P}(X_{j}^{(i)}=x_{j}^{(i)}\\mid X_1=x_1^{(i)},\\ldots, X_{j-1}=x_{j-1}^{(i)},X_{j+1}=x_{j+1}^{(i-1)},\\ldots,X_v=x_v^{(i-1)})$ for $j=1,2, \\ldots v$, which then generates a new state for the network.\n",
    "\n",
    "There is also another variation of the Gibbs sampler called the **random scan** where the update of the state of the vertex is not in a cycle but done in a random manner. Below are some functions that are defined for the implementation of the Gibbs sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Takes in a vector x and returns its sigmoid activation.\n",
    "    Input:\n",
    "    - x: a numpy array\n",
    "    \"\"\"\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def single_unit_update(initialState, W, b, v):\n",
    "    \"\"\"\n",
    "    Returns the new states and the state of the vth vertex that has been updated conditioned on the other units\n",
    "    Input:\n",
    "    - initialState: a numpy array of binary values denoting the initial state of the nodes.\n",
    "    - W: a 2d numpy array of values that the prior distribution is based from.\n",
    "    - v: (int) the state of the vertex to be updated.\n",
    "    \"\"\"\n",
    "    stateSize = initialState.shape\n",
    "    newState = np.zeros(stateSize) + initialState\n",
    "#     Here we see that to update a single vertex state we only use the weights Wij for i not\n",
    "#     equal to j and hence the reason to set the diagonals to be zero earlier. But since\n",
    "#     we did not we have to kill off the diagonals of W here.\n",
    "#     prob = sigmoid((W - (W * np.eye(stateSize))).dot(initialState))\n",
    "    prob = sigmoid(W.dot(initialState) + b)\n",
    "    newState[v] = np.random.binomial(1, prob[v], 1)\n",
    "    return newState, newState[v]\n",
    "\n",
    "\n",
    "def gibbs_sample(initialState, W, b):\n",
    "    \"\"\"\n",
    "    Returns the new state of the network after updating all v units systematically, given an initialized state\n",
    "    of the network and weight matrix W.\n",
    "    Input:\n",
    "    - initialState: a numpy array of binary values denoting the initial state of the nodes.\n",
    "    - W: a 2d numpy array.\n",
    "    \"\"\"\n",
    "#     print ('initialState:', initialState)\n",
    "    stateSize = initialState.shape\n",
    "    newState = np.zeros(stateSize)\n",
    "    for i in range(stateSize[0]):\n",
    "#         print ('Changing the state for unit %d...'% i)\n",
    "        initialState, vertexState = single_unit_update(initialState, W, b, i)\n",
    "#         print ('Old unit state is %d, new unit state is %d'% (initialState[i], unitState))\n",
    "        newState[i] = vertexState\n",
    "#     print ('newState:', newState)\n",
    "    return newState\n",
    "\n",
    "\n",
    "def multi_gibbs_sample(initialState, W, b, n):\n",
    "    \"\"\"\n",
    "    Performs Gibbs sampling n times with a given initial state and weight matrix W\n",
    "    and stores each sample as a row.\n",
    "    Input:\n",
    "    - initialState: a numpy array of binary values denoting the initial state of the nodes.\n",
    "    - W: a 2d numpy array.\n",
    "    - n: (int) number of samples to be drawn.\n",
    "    \"\"\"\n",
    "    stateSize = initialState.shape[0]\n",
    "    sample = np.zeros((n, stateSize))\n",
    "    for i in range(n):\n",
    "        sample[i, :] = gibbs_sample(initialState, W)\n",
    "    return sample\n",
    "\n",
    "def rand_gibbs_sample(initialState, W, b, n):\n",
    "    \"\"\"\n",
    "    Does a random scan Gibbs sampling n times with a given initial state and weight matrix W.\n",
    "    - initialState: a numpy array of binary values denoting the initial state of the nodes.\n",
    "    - W: a 2d numpy array.\n",
    "    - n: (int) number of samples to be generated.\n",
    "    \"\"\"\n",
    "#     v = W.shape[0]\n",
    "#     sample = np.zeros((n, initialState.shape[0]))\n",
    "    for i in range(n):\n",
    "        s = np.random.randint(0, v)\n",
    "        initialState, vertexState = single_unit_update(initialState, W, b, s)\n",
    "#         sample[i, :] = gibbs_sample(initialState, W)\n",
    "    return initialState\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To make ensure that the sample that we obtain are independent and identically distributed, we do a **burn-in** of $10000\\times v$ iterations so that the samples obtained follow the distribution of the weight matrix, following which we pick a sample for every $1000 \\times v$ iterations, which is called **mixing-in**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling using random scan Gibbs sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn-in state:  [[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Burn-in\n",
    "burnin_state = rand_gibbs_sample(initialState, W, b, 10000 * v)\n",
    "print ('Burn-in state: ', burnin_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mixing-in\n",
    "def mixin_gibbs_sample(initialState, W, b, n, m, savesamples = 'True'):\n",
    "    \"\"\"\n",
    "    Does a random scan Gibbs sampling n * m times with a given initial state and weight matrix W and \n",
    "    stores a sample every m iterations.\n",
    "    - initialState: a numpy array of binary values denoting the initial state of the nodes.\n",
    "    - W: a 2d numpy array. \n",
    "    - n: (int) number of samples to be drawn.\n",
    "    - m: (int) number of iterations before a sample is drawn.\n",
    "    - savedate: (bool) save samples as 'samples.dat.npy' if True and does not save if false.\n",
    "    \"\"\"\n",
    "    tic = time.time()\n",
    "           \n",
    "    v = W.shape[0]\n",
    "    sample = np.zeros((n, initialState.shape[0]))\n",
    "    for i in range(n):\n",
    "        initialState = rand_gibbs_sample(initialState, W, b, m)\n",
    "        sample[i, :] = initialState.reshape(v,)\n",
    "    if savesamples == \"True\":\n",
    "        np.save('gibbs-sample.dat', sample)\n",
    "        print ('Samples are saved as \"gibbs-sample.dat.npy\"')\n",
    "    elif savesamples == \"False\":\n",
    "        print ('Samples were not saved. Run np.save(\"gibbs-sample.dat\", sample) to save them. ')\n",
    "    else:\n",
    "        raise ValueError(\"savesamples must be 'True' or 'False'\")\n",
    "    \n",
    "    toc = time.time()\n",
    "    print ('Time taken to create %d samples is %f minutes' % (n, (toc - tic)/60))\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples were not saved. Run np.save(\"gibbs-sample.dat\", sample) to save them. \n",
      "Time taken to create 50000 samples is 2.390260 minutes\n"
     ]
    }
   ],
   "source": [
    "sample = mixin_gibbs_sample(burnin_state, W, b, 50000, 100, savesamples='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized W matrix:  [[  0.00000000e+00   6.68011930e-01   1.94882962e+00  -2.91452371e+00\n",
      "    5.14409977e-01  -1.60142727e+00  -1.30098843e+00  -1.80926089e+00\n",
      "    3.80025718e-03  -1.20009567e-01   2.98940728e-01   2.54700910e-01\n",
      "    1.13594056e+00   6.64679065e-02  -1.14605111e+00  -2.43599888e+00]\n",
      " [ -2.41625312e-01   0.00000000e+00   6.59191352e-01  -4.19087629e+00\n",
      "   -1.86811557e+00  -4.13004796e-01   5.48789388e-01  -7.16728445e-01\n",
      "   -5.21009731e-01  -3.98040472e-01  -1.07090084e-01   8.94378669e-01\n",
      "   -1.26866342e+00  -2.79719062e-01  -2.25892214e+00  -1.71338657e+00]\n",
      " [  3.22721400e-01  -5.72796298e-02   0.00000000e+00  -2.11366921e+00\n",
      "   -1.39691385e+00  -2.55034889e-01  -1.85262868e+00  -1.25827067e+00\n",
      "   -7.04001814e-01  -1.44262705e+00   1.71073877e-01  -1.09564734e+00\n",
      "    1.38119234e+00  -2.10309797e+00  -1.31938538e-02  -1.93764574e+00]\n",
      " [  2.61903092e-01  -1.04812244e-01   2.68886581e+00   0.00000000e+00\n",
      "   -1.45882648e+00   2.45788371e-03  -5.26186158e-01  -1.65031729e+00\n",
      "    1.11058410e+00   4.66817524e-01  -3.13310042e-02   2.85859275e-01\n",
      "   -5.57926345e-01   1.64789513e+00  -3.08302963e+00  -8.52555342e-02]\n",
      " [  9.68429057e-01  -5.04459245e-01   6.83213454e-01  -4.18123420e+00\n",
      "    0.00000000e+00   5.98495181e-01  -4.75928668e-01   4.32384049e-02\n",
      "    1.45646552e+00   4.57555116e-01   1.17829809e+00  -4.79107801e-01\n",
      "   -2.36205812e-01  -1.22558326e+00  -1.07128728e+00  -1.09619514e+00]\n",
      " [ -1.05910455e+00   1.03895516e+00   1.91339605e+00  -2.63164620e+00\n",
      "    6.86798814e-01   0.00000000e+00  -8.41326499e-01   9.70720460e-02\n",
      "    1.30500316e-01  -1.45662457e-01   1.43753285e+00  -7.55173181e-01\n",
      "    1.85956266e-01  -1.15680022e+00  -1.30432188e+00  -2.03976695e+00]\n",
      " [ -4.46252790e-01   2.31316227e+00   6.28215185e-01  -2.84787732e+00\n",
      "   -7.52121066e-02  -5.28913571e-01   0.00000000e+00  -1.11089920e+00\n",
      "   -1.52703379e+00   7.01075925e-01  -9.02291771e-01   6.46135281e-01\n",
      "   -2.95820144e-01   1.38323134e-01  -2.58687832e+00  -2.04086361e+00]\n",
      " [ -8.34108342e-01   1.16806135e+00   1.34299011e+00  -3.85159153e+00\n",
      "    5.64371877e-01   5.29901885e-01  -9.90482292e-01   0.00000000e+00\n",
      "   -7.74431231e-01   6.40920810e-01  -1.35619909e-01  -3.42047091e-01\n",
      "   -1.31317419e+00  -6.72318019e-01  -1.08833559e+00  -2.49049857e+00]\n",
      " [  3.72042105e-01   7.56869360e-01   1.29034826e+00  -1.69760085e+00\n",
      "    1.37068829e+00  -4.35805488e-02  -2.01352758e+00  -1.38134193e+00\n",
      "    0.00000000e+00  -7.68514881e-01   1.28822940e+00   1.07866873e+00\n",
      "    5.36485074e-01  -1.04072579e+00  -1.41887570e+00  -8.96085748e-01]\n",
      " [ -2.81221389e-01   3.50384948e-01   2.22693547e-02  -2.87082110e+00\n",
      "   -1.57675786e-01  -8.49196992e-01  -3.14871538e-01  -4.95443564e-01\n",
      "   -1.29796855e+00   0.00000000e+00   1.14396170e+00   1.75812679e+00\n",
      "   -3.72493964e-01  -8.06841319e-01  -1.42170055e+00  -2.95626944e-01]\n",
      " [ -1.76291535e-01   3.27314896e-01   1.32194984e+00  -3.68299007e+00\n",
      "    2.49046743e-01   4.19977879e-01  -2.23225968e+00  -1.58600472e+00\n",
      "    4.44755289e-01   8.29941258e-01   0.00000000e+00   7.08418468e-01\n",
      "    1.25041086e+00  -1.02757784e+00  -2.52818624e+00  -1.67279011e+00]\n",
      " [ -7.09674979e-02   1.47834750e+00   2.04792478e-01  -3.21623593e+00\n",
      "   -1.25879529e+00  -1.62316430e+00  -5.34268769e-01  -1.64286805e+00\n",
      "    3.84758473e-01   1.59367021e+00   8.57982322e-01   0.00000000e+00\n",
      "   -2.12667754e+00  -1.23281253e-03  -2.41257491e+00  -2.27226990e+00]\n",
      " [  1.17717639e+00  -3.17790350e-01   3.04853640e+00  -3.69311732e+00\n",
      "   -6.48989064e-01  -3.15130619e-01  -1.10931996e+00  -2.24709091e+00\n",
      "    2.09479054e-01  -1.70046314e-01   1.76687895e+00  -1.75977330e+00\n",
      "    0.00000000e+00  -1.13477314e-02  -3.73889040e-01  -1.27706267e+00]\n",
      " [  5.16473481e-01   1.07992376e+00  -2.69841702e-02  -1.07852609e+00\n",
      "   -1.22959676e+00  -1.24911736e+00  -2.66406932e-01  -1.19746500e+00\n",
      "   -9.58962063e-01  -1.95623922e-01  -1.02339999e-01   7.74441171e-01\n",
      "    3.97422015e-01   0.00000000e+00  -1.20775530e+00  -2.14122366e+00]\n",
      " [  7.65305375e-01   5.62071596e-01   3.52427086e+00  -4.34809994e+00\n",
      "    3.86050133e-01   6.47118928e-02  -1.53025747e+00  -1.52131657e-01\n",
      "    1.24238942e-01   6.50867760e-01  -1.41597490e-01  -1.75550016e-01\n",
      "    1.49623162e+00   2.53595610e-01   0.00000000e+00  -2.90055130e+00]\n",
      " [ -7.47193090e-01   8.85056461e-01   1.37726827e+00  -1.57287655e+00\n",
      "    1.38591572e-01  -8.93283871e-01  -1.20679347e+00  -1.77684533e+00\n",
      "    4.24478191e-01   1.55439067e+00   4.91247936e-01  -2.57795707e-01\n",
      "    3.70507285e-01  -9.02423452e-01  -3.12310201e+00   0.00000000e+00]]\n",
      "Initialized bias:  [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Burn-in state:  [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "run mpfgibbs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
